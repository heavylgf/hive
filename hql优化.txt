  1. 在编写带有join操作的代码语句时，应该将条目少的表/子查询放在join操作符的左边。因为在reduce阶段，位于join操作符左边的表的内容会被加载进内存，载入条目较少的表可以有效减少内存溢出。所以对于同一个key来说，对应的value值小的放前，大的放后。即小表放前原则。hive较高版本已经不用这样的原则了，会自动识别
  2. 参数详解：hive.merge.size.per.task(默认是256M)：merge job后每个文件的目标大小，用之前job输出文件的total size除以这个值，就可以决定merge job的reduce数目。merge job的map端相当于identity map，然后shuffle到reduce，每个reduce  dump一个文件，通过这种方式控制文件的数量和大小。   mapred.task.timeout：默认600000ms，如果map或者reduce方法在600秒内没有返回或者输出内容，TaskTracker将认为相应的map或者reduce已经死亡。并向JobTracker汇报错误。JobTracker会杀死此次尝试，并在其他节点上重新执行它。 hive.skewjoin.key:这个是join键对应的记录条数超过这个值则会进行分拆。hive.optimize.skewjoin：设置为true，会对数据倾斜进行优化。hive.merge.mapredfiles:是否启动merge job来合并reduce端输出的结果，建议开启。hive.groupby.skewindata：如果在group by中出现倾斜，应该设置成true。hive.exec.parallel：这个参数控制在同一个sql中的不同job是否可以同时运行，提高作业的并发。hive.tez.auto.reducer.parallelism=false;设置reduce端的输出是否可以并行，默认是false。mapreduce.output.fileoutputformat.compress.codec设置job的输出结果的压缩方式。hive.exec.compress.output：设置job的输出结果是否是压缩的，默认是false。   mapreduce.output.fileoutputformat.compress：设置Mapreduce job的结果输出是否需要使用压缩。hive.exec.compress.intermediate：决定查询的中间map/reduce job （中间 stage）的输出是否为压缩格式。
  3. left semi join   A left semi join B on A.id = B.id 如果A中有10条记录，B中也有10条记录，返回的结果是根据A表中的记录数决定的，也就是10条，即使是m:n的关系。
  4. 如果一个表中的map数特别多，可能是由于文件个数特别多，而且文件特别小造成的，可以设置如下参数，合并文件：set mapred.max.split.size=100000000; // 100M                                                                                              set mapred.min.split.size.per.node=100000000;                                                                                                                                                set mapred.min.split.size.per.rack=100000000;                                                                                                                                   set  hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; //合并小文件。
  5. 如果一个表中只有一个文件，大小为120M，包含几千万条记录，可以考虑用多个map任务完成:                               set mapred.reduce.tasks=10; 
  6. hive确定reduce数，reduce的个数基于以下参数设定hive.exec.reducers.bytes.per.reducer(每个reduce任务处理的数据量，默认为10^3=1000=1G)  hive.exec.reducers.max(每个任务最大的reduce数，默认是999)。如果reduce的输入（map的输出）总大小不超过1G,那么只会有一个reduce任务；所以调整以下参数：                         set .reducers.bytes.per.reducer=500000000; （500M）   set mapred.reduce.tasks = 15;
  7. 设计和使用bucket：buckets对指定列计算hash，根据hash值切分数据，目的是为了并行，每一个bucket对应一个文件。所用场合：对某一列进行分区，比如对用户ID进行分区:create table xxxx(userid int,url string,ip string) partitioned by (ds string) clustered by(userid) into 32 BUCKETS; 按照日期进行分区然后再按照userid把日志放入32个篮子里。插入数据的时候：SET hive.enforce.bucketing = true; insert overwrite table xxxx partition(ds='xxxx') select ......from table where dt = 'xxxx'.
  8. count(distinct):当count(distinct )记录非常多的时候，设置以下两个参数：set map.aggr=true;
  9. group by:  group by 的方法是在reduce做一些操作，这样会导致两个问题：map端聚合，提前一部分计算：hive.map.aggr = true 同时设置时间间隔：hive.groupby.mapaggr.checkinterval  均衡处理：hive.groupby.skewindata   这个是针对数据倾斜的，设置为true的时候，任务的reduce会把原来的一个job拆分成两个，第一个的job中reduce处理不同的随机分发过来的key数据，生成中间结果，再由最后一个综合处理。
  10. order by,sort by,distribute by ,cluster by:  order by 是在全局的排序，只用一个reduce去跑，所以在set hive.mapred.mode=strict模式下，order by 必须limit ，否则报错。sort by 只保证同一个reduce下排序正确。distribute by是按照指定的列把map输出结果分配到reduce里，所以经常和sort by 来实现对某一个字段的相同值分配到同一个reduce排序。cluster by 实现了distribute by + sort by 的功能
  11. 数据倾斜：如果出现数据倾斜应该做以下操作：set hive.exec.reducers.max=200;  set mapred.reduce.tasks= 200;---增大Reduce个数  set hive.groupby.mapaggr.checkinterval=100000 ;这个是group by的键对应的记录数超过这个值会进行拆分，值根据具体的数据量设置。set hive.groupby.skewindata=true; （group by出现倾斜）set hive.skewjoin.key=100000;--这个是join的键对应的记录条数超过这个值会进行拆分，值根据具体数据量设置
  12. 如果union all的部分个数大于2，或者每个union部分数据量大，应该拆分成多个insert语句，实际测试过程中，执行时间能提升50%。
  13. hive.optimize.cp=true;列裁剪(减少不必要列的扫描) hive.optimize.prunner分区剪裁(减少不必要的分区的扫描)； hive.limit.optimize.enable=true(优化limit语句);
  14. hive.map.aggr=true;开启会使map端进行聚合操作，提升整体性能，但需要更多的内存。
  15. 合并小文件：hive.merg.mapfiles=true(合并map输出)  hive.merge.mapredfiles=false(合并reduce输出) hive.merge.size.per.task=256*1000*1000(合并文件的大小)  hive.merge.smallfiles.avgsize=16000000:文件的平均大小小于该值的时候，会启动一个MR任务执行MR。
  16. 减少map数：set mapred.max.split.size  set mapred.min.split.size　set mapred.min.split.size.per.node   set mapred.min.split.size.per.rack　set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat 增加map数：当input的文件都很大，业务逻辑复杂，map执行的非常缓慢的时候，可以考虑增加map数，使得每个map处理的数据量减少，从而提高任务的执行效率：如果一个表只有一个文件，大小为120M，但是包含了几千万的数据量，如果一个map去完成这个任务，肯定是比较耗时的，这种情况下我们要考虑将一个文件拆分成多个，这样就可以用多个map
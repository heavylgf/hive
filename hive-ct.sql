hadoop fs  -mkdir /hive;hadoop fs  -mkdir /hive/halllogin;hadoop fs  -mkdir /hive/roomlogin;dfs -rm /hive/halllogin/;####联合查询select * from 			(select userId from table_a where dt=20160731) a 		join 			(select userId from table_b where dt=20160731) b  		on a.userId=b.userId 		join 			(select userId from table_c where dt=20160731) c 		on a.userId=c.userId注意：/data/halllogin/20170110 文件用户是hdfs/hive/halllogin 目录用户是root直接可以再root用下 -cp 不用切换用户  cp完成之后文件的用户是roothive> hadoop fs -cp /data/halllogin/ /hive/halllogin;hive> hadoop fs -cp /data/roomlogin/ /hive/roomlogin;create database loginDB;use loginDB;use loginDB;drop table if exists halllogin_detail;create table halllogin_detail (uid                   int,date                  int,time                  int,ip                     string, group                  int,  app                    int,fromapp                int,game                   int, channel                int,promcode               int,hardid                 string,    area_province          string,area_city              string,area_district          string)  PARTITIONED BY (dt     string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';create table emp(name string,salary bigint)partitioned by(dt string)row format delimited fields terminated by ' ';desc emp;show partitions emp;hadoop fs -put localfile /user/root/*** 。LOAD DATA  INPATH '/hive/halllogin/20170101' overwrite  INTO TABLE halllogin_detail PARTITION (dt='20170101'); drop table if exists roomlogin_detail;create table roomlogin_detail (uid                   int,date                  int,time                  int,ip                     string, group                  int,  app                    int,utype                  int,game                   int, code                   string,room                   int,channel                int,promcode               int,hardid                 string,area_province          string,area_city              string,area_district          string)  PARTITIONED BY (dt     string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';LOAD DATA  INPATH '/hive/roomlogin/20170101' overwrite  INTO TABLE roomlogin_detail PARTITION (dt='20170101'); select count(*) from business.halllogin_log where dt>='20171001' and dt<'20171031'; --252626488select count(*) from business.halllogin_log where dt>='20171001' and dt<='20171031'; --260796239select count(*) from business.halllogin_log where dt='20171031'; --	8169751####将hdfs上数据复制到本地文件get命令hadoop fs -get /user/hadoop/file localfilehadoop fs -get hdfs://host:port/user/hadoop/file localfilehadoop fs -get /hive/halllogin/20170114 20170114hadoop fs -get /hive/halllogin/20170115 20170115copyToLocal命令除了限定目标路径是一个本地文件外，和get命令类似。使用方法：hadoop fs -copyToLocal [-ignorecrc] [-crc] URI <localdst>使用上边的hadoop fs -get url localurl 来拷贝大文件到本地的话很容易中途断掉。原因是：文件过大，拷贝时间过长，一旦shell客户端的网络状况不良则会拷贝中断。（..+ &）将当前任务提交给后台，让后台去执行。从而使这个任务在本地执行，不停止/重启hadoop则不会拷贝中断。 解决方法：在命令末尾加 & 符号。 eg：hadoop fs -get /xxx/bb /yyy/aa &####  将本地目录下文件复制到HDFS文件夹下copyFromLocal命令记住先切换用户 su hdfs hadoop fs -copyFromLocal /opt/20170114 /hive/halllogin;put命令   使用方法：hadoop fs -put <localsrc> ... <dst>从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。hadoop fs -put localfile /user/hadoop/hadoopfilehadoop fs -put localfile1 localfile2 /user/hadoop/hadoopdirhadoop fs -put localfile hdfs://host:port/hadoop/hadoopfilehadoop fs -put - hdfs://host:port/hadoop/hadoopfile ####  将数据从hive里导出到本地insert overwrite local directory 'path' select q1;  注意：不能使用insert into local directory 'path' select q1 这种方式      和Hive数据导入不一样，不能使用INSERT INTO命令导出表中数据。指定输出结果列之间的分隔符insert overwrite local directory 'path'  row format delimited  fields terminated by '\t' select q1;insert overwrite local directory '/opt/test'  row format delimited  fields terminated by ',' select uid,date,time,ip, group,code,room from roomlogin_detail WHERE app=1880077 AND `date`>=20170801;将数据从hive里导出到hdfs  会产生很多小文件insert overwrite directory 'hdfs_path' select * from dept;####  hive本地机器执行hive -e导出数据到本地文件：得到的结果是用\t分割的。http://blog.csdn.net/niityzu/article/details/42238483hive -e "use logindb;select * from logindb.halllogin_detail where dt='20170114' limit 10" > /opt/bb;  hive -e " use logindb;select uid, hardid,date,channel,group from logindb.halllogin_detail where app = 3001 and dt>='20170601' and dt<='20171120' " > /opt/app_3001; hive -f方式：hive -f wyp.sql >> local/wyp2.txtcat wyp.sqlselect * from wyp# 统计部署实例select count(1),a.APP_ID from t_app_conf c, t_app a where c.VALID_FLAG = 1 and c.APP_ID = a.APP_ID group by a.APP_ID;#统计应用名，应用负责人select a.APP_NAME,u.login_name from t_app a LEFT JOIN s_sg_user u on a.APP_MANAGER = u.id;#统计最新版本select max(v.ver_num),a.app_id from t_app a ,t_app_version v where a.APP_ID = v.APP_ID group by a.APP_ID order by v.CREATE_DATE desc LIMIT 1;####  Load：加载文件到hive表：hive> LOAD DATA LOCAL INPATH '/opt/cloudy/data' INTO TABLE track_log PARTITION （这个字段代表分区表）(ds='2015-08-28');       (ds='2015-08-28' 是指定字段的格式)   加载该目录下全部文件 或者hive> LOAD DATA LOCAL INPATH '/opt/cloudy/data/2015082818' INTO TABLE track_log PARTITION (ds='2015-08-28');如上两个方式是append方式，overwrite 的方式如下：1、针对本地文件2015082818和2015082819文件上传到 /usr/local目录下load data local inpath '/usr/local/2015082818' overwrite into table track_log partition (ds='2015-08-28', hour = '18');load data local inpath '/usr/local/2015082819' overwrite into table track_log partition (ds='2015-08-28', hour = '19');hive> LOAD DATA LOCAL INPATH '/opt/cloudy/data/2015082818' overwrite  INTO TABLE track_log PARTITION (ds='2015-08-28',hour='18');hive> LOAD DATA LOCAL INPATH '/opt/cloudy/data/2015082819' overwrite  INTO TABLE track_log PARTITION (ds='2015-08-28',hour='19');2、针对hdfs上文件：hive> LOAD DATA  INPATH '/opt/cloudy/data/2015082818' overwrite  INTO TABLE track_log PARTITION (ds='2015-08-28',hour='18');hive> LOAD DATA  INPATH '/opt/cloudy/data/2015082819' overwrite  INTO TABLE track_log PARTITION (ds='2015-08-28',hour='19');su flumehive -e "LOAD DATA  INPATH '/hive/roomlogin/20170114' overwrite  INTO TABLE roomlogin_detail PARTITION (dt='20170114')"create database HappyCoinDB;use HappyCoinDB;欢乐币GsHappyCoinDBorderdetails{    "_id" : "5922c23686a25e2ce0e3cde4",    "ordercode" : "5922c23686a25e2ce0e3cde4",    "operatecode" : 205001,    "uid" : 132155293,    "amountabs" : NumberLong(1),    "amount" : NumberLong(-1),    "date" : 20170522,    "time" : 184926,    "fromtype" : 400,    "app" : NumberLong(1880392),    "game" : 392,    "group" : 6,    "channel" : 10063,    "relateorder" : "5922c23686a25e2ce0e3cde4",    "busiorder" : "teste6r1xxxadx3ytt2566C20170522",    "updatets" : NumberLong(1508314340087),    "appbygame" : 1880392}drop table if exists orderdetails;create table orderdetails (uid                   int,date                  int,time                  int,ordercode    		  string,operatecode  		  int,app       			  int,group    			  int,game    			  int,channel    			  int,amountabs   		  int,amount     			  int,relateorder   		  string,updatets     		  int,busiorder    		  string,fromtype     		  int,appbygame             int) PARTITIONED BY (dt     string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';LOAD DATA  INPATH '/hive/happycoin/orderdetails/201711' overwrite  INTO TABLE happycoindb.orderdetails PARTITION (dt='201711'); drop table if exists opdetails;create table opdetails (uid                   int,date                  int,time                  int,ordercode    		  string,operatecode   		  int,app  				  int,group       		  int,game  				  int,channel  			  int,amountabs   		  int,amount   			  int,relateorder  		  string,updatets   			  int,busiorder   		  string,fromtype   			  int,appbygame   		  int,uidfrom   			  int,dealerid   			  int,cardno    			  string,cardtype   			  int,dealerarea_province   string,dealerarea_city       string,dealerarea_district   string) PARTITIONED BY (dt     string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';LOAD DATA  INPATH '/hive/happycoin/opdetails/201711' overwrite  INTO TABLE happycoindb.opdetails PARTITION (dt='201711'); opdetails{    "_id" : ObjectId("59300c748176102e5b019384"),    "ordercode" : "5922c08786a25e2fc0220b85",    "operatecode" : 206001,    "uid" : 179409653,    "amountabs" : NumberLong(200),    "amount" : NumberLong(-200),    "date" : 20170522,    "time" : 184215,    "fromtype" : 999,    "app" : NumberLong(1880039),    "game" : 39,    "dealerid" : 114,    "cardno" : "411800010805",    "cardtype" : 2501,    "updatets" : NumberLong(1508314206340),    "appbygame" : 1880039}/* 41 */{    "_id" : ObjectId("59300c748176102e5b01938d"),    "ordercode" : "5922c19386a25e2fc0220b8d",    "operatecode" : 205001,    "uid" : 180268372,    "amountabs" : NumberLong(30),    "amount" : NumberLong(-30),    "date" : 20170522,    "time" : 184643,    "fromtype" : 999,    "app" : NumberLong(1880039),    "game" : 39,    "updatets" : NumberLong(1508314206340),    "appbygame" : 1880039}/* 42 */{    "_id" : ObjectId("59300c748176102e5b019392"),    "ordercode" : "5922c23686a25e2ce0e3cde4",    "operatecode" : 205001,    "uid" : 132155293,    "amountabs" : NumberLong(1),    "amount" : NumberLong(-1),    "date" : 20170522,    "time" : 184926,    "fromtype" : 400,    "app" : NumberLong(1880392),    "game" : 392,    "uidfrom" : 74591377,    "dealerid" : 50,    "cardno" : "411100010037",    "group" : 6,    "channel" : 10063,    "updatets" : NumberLong(1508314180785),    "appbygame" : 1880392}create database paydb;use paydb;充值数据：paydbdrop table if exists basic;create table basic (orderno				string,payway				int,	paywaydetail		int,product				int,paydate				int,payts				bigint,group				int,paychann			int,partnermode			int,partnerclient  		int,platform			int,app					bigint,appchannel			int,appvers				string,clientcode			int,price				bigint,money				bigint,vctype				int,vcnum				bigint,uidto				int,uidfrom				int,ip					string,discount			bigint,game				int,reggroup			int,pay1st				boolean,regdate  			int,area_province 		string,area_city			string,area_district		string)PARTITIONED BY (dt     string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';LOAD DATA  INPATH '/hive/happycoin/opdetails/201711' overwrite  INTO TABLE happycoindb.opdetails PARTITION (dt='201711'); create database silverlogdb;use silverlogdb;银子流水数据：silverlogdbdrop table if exists silverlog;create table silverlog (uid    int,gameid int,opid   int,deposit int,balance bigint,ip  string,date  int,time  int,desc  string,optype int,diff int,guid string,area-province string,area-city string,area-district string,logsource string)PARTITIONED BY (dt     string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';LOAD DATA  INPATH '/hive/happycoin/opdetails/201711' overwrite  INTO TABLE happycoindb.opdetails PARTITION (dt='201711'); uid	int	2	game	int	3	opid	int	4	deposit	int	5	balance	int	6	ip	string	7	date	int	8	time	int	9	desc	string	10	type	int	11	diff	int	12	guid	string	13	area_province	string	14	area_city	string	15	area_district	string	16	dt	stringcreate database GsPlayTogetherDB;use GsPlayTogetherDB;drop table if exists endbout;create table endbout (uid 			int,gamecode		string,gameid 	int,app  int,roomtype  int,roomid		string,roomno		int,group		int,date		int,time		int,updatets	bigint,cost		int,score		int,winflag		int,message		string,boutcode	string,logincode		string)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';drop table if exists endroom;create table endroom (gamecode		string,gameid		int,app bigint,roomtype		int,roomid		string,roomno		int,date		int,time		int,updatets		bigint,userdetails_uid	int,userdetails_group		int,userdetails_logincode		string)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';drop table if exists gameactive;create table gameactive (uid	int,hardid	string,gamecode	string,gameid		int,app		bigint,roomtype		int,roomid		string,roomno		int,group		int,date		int,time		int,ip		string,updatets		bigint,msgcode		string,logincode		string,imei	string,wifi	string,imsi	string,sim		string,system	string,province	string,city	string,district	string)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';drop table if exists tcyappactive;create table tcyappactive (uid	int,hardid	string,group	int,channel	int,promcode	int,vers	string,date	int,time	int,ip	string,updatets	bigint,imei	string,wifi	string,imsi	string,sim	string,system	string,area_province	string,area_city	string,area_district	string)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';drop table if exists validroom;create table validroom (gamecode	string,gameid	int,app	bigint,roomtype	int,roomid	string,roomno	int,date	int,time	int,updatets	bigint,userdetails_uid	int,userdetails_group	int,userdetails_logincode	string)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';LOAD DATA  INPATH '/hive/happycoin/opdetails/201711' overwrite  INTO TABLE happycoindb.opdetails PARTITION (dt='201711'); ## 创建临时表drop table if exists temporary;create table temporary (uid	int,depositsum	bigint)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';游戏时长数据：logoutdetaildrop table if exists logoutdetail;create table logoutdetail (uid	int,game	int,app	bigint,code	string,room	int,ip	string,utype	int,promcode	int,channel	int,group	int,imei	string,wifi	string,imsi	string,sim	string,	system	string,hardid	string,stay	bigint,province	string,city	string,district	string,date	int,time	int,updatets	bigint)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';注册用户数据：create database RegDB;{    "_id" : 325936,    "date" : 20161011,    "time" : 120105,    "ip" : "122.224.230.90",    "group" : 66,    "game" : 10000,    "app" : NumberLong(3001),    "hard1st" : true,    "hardid" : "357784056799875",    "channel" : 310200,    "promcode" : 310198,    "province" : "06",    "city" : "0601",    "hardarea" : {        "province" : "06",        "city" : "0601",        "district" : "060107"    },    "mobilehard" : {        "imei" : "357784056799875",        "imsi" : "460017175914586",        "sim" : "89860114836021109021",        "system" : "6ba9acee9d109c12",        "wifi" : "D022BEB10AC6"    },    "district" : "060107"}drop table if exists regdetail;create table regdetail (uid int,  用户序号date int, 注册时间time int,ip string, 注册ipgroup intgame int,  游戏idapp bigint,  应用idhard1st string,hardid string,  设备号码channel int,    渠道号promcode int,province string,city string,district string,hardarea_province string,hardarea_city string,  设备注册地区hardarea_district string,mobilehard_imei string,mobilehard_imsi string,mobilehard_sim string,mobilehard_system string,mobilehard_wifi string)PARTITIONED BY (dt    string)ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';注册用户明细：、、、应用名称、大厅ID、大厅名称、、渠道名称、所属渠道标签、推广码、总游戏时长、总大厅时长、设备重复注册、 、、、账号注册地区、设备注册地区。注册用户明细：用户序号、游戏ID、应用ID、应用名称、大厅ID、大厅名称、渠道号、渠道名称、所属渠道标签、推广码、总游戏时长、总大厅时长、设备重复注册、设备号、账号注册时间、账号注册IP、账号注册地区、设备注册地区。 